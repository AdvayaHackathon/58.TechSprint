Question: What is artificial intelligence?
Answer: Artificial Intelligence (AI) refers to the simulation of human intelligence in machines that are programmed to think and act like humans. These machines are designed to mimic cognitive functions such as learning, problem-solving, and decision-making.
Marks: 2

Question: Who coined the term "Artificial Intelligence"?
Answer: The term "Artificial Intelligence" was coined by John McCarthy in 1956 at the Dartmouth Conference.
Marks: 1

Question: What are the main types of AI?
Answer: The main types of AI are: 1) Narrow or Weak AI, which is designed for a specific task, 2) General or Strong AI, which can perform any intellectual task that a human can do, and 3) Artificial Superintelligence, which would surpass human intelligence.
Marks: 3

Question: Explain the Turing Test.
Answer: The Turing Test, proposed by Alan Turing in 1950, is a test of a machine's ability to exhibit intelligent behavior equivalent to, or indistinguishable from, that of a human. In the test, a human evaluator would judge natural language conversations between a human and a machine designed to generate human-like responses.
Marks: 2

Question: What is machine learning?
Answer: Machine Learning is a subset of AI that provides systems the ability to automatically learn and improve from experience without being explicitly programmed. It focuses on the development of computer programs that can access data and use it to learn for themselves.
Marks: 2

Question: Describe the three main types of machine learning.
Answer: The three main types of machine learning are: 1) Supervised Learning, where the algorithm learns from labeled data, 2) Unsupervised Learning, where the algorithm finds patterns in unlabeled data, and 3) Reinforcement Learning, where the algorithm learns through interaction with its environment.
Marks: 3

Question: What is deep learning?
Answer: Deep Learning is a subset of machine learning that uses artificial neural networks with multiple layers (hence "deep") to progressively extract higher-level features from raw input. It's particularly effective for tasks like image and speech recognition.
Marks: 2

Question: Explain the concept of neural networks.
Answer: Neural networks are computing systems inspired by the biological neural networks in animal brains. They consist of interconnected nodes (neurons) organized in layers. Each connection can transmit a signal to other neurons. An individual neuron may receive, process, and transmit signals to neurons it's connected to.
Marks: 3

Question: What is natural language processing (NLP)?
Answer: Natural Language Processing is a branch of AI that focuses on the interaction between computers and humans using natural language. The ultimate objective of NLP is to read, decipher, understand, and make sense of human language in a valuable way.
Marks: 2

Question: What are some applications of AI in everyday life?
Answer: AI applications in everyday life include virtual assistants (like Siri or Alexa), recommendation systems (used by Netflix, Amazon), facial recognition, spam filters in email, autonomous vehicles, predictive text, and smart home devices.
Marks: 3

Question: What is the difference between strong AI and weak AI?
Answer: Weak AI, also known as narrow AI, is designed to perform a specific task (like facial recognition). Strong AI, also known as Artificial General Intelligence (AGI), refers to a machine with consciousness, sentience, and mind, with the ability to solve any problem that a human can.
Marks: 2

Question: Explain the concept of fuzzy logic in AI.
Answer: Fuzzy logic is a method of reasoning based on "degrees of truth" rather than the usual "true or false" (1 or 0) Boolean logic. It allows for partial truths and multi-valued logic, making it useful for handling uncertainty and imprecision in AI systems.
Marks: 2

Question: What is the role of heuristics in AI?
Answer: Heuristics in AI are problem-solving techniques that use practical methods or various shortcuts to produce solutions that may not be optimal but are sufficient for immediate goals. They're often used when an exhaustive search is impractical, helping to reduce the search space and find approximate solutions quickly.
Marks: 2

Question: Describe the concept of a genetic algorithm.
Answer: A genetic algorithm is a search heuristic inspired by Charles Darwin's theory of natural evolution. It reflects the process of natural selection where the fittest individuals are selected for reproduction to produce offspring of the next generation, often used for optimization problems in AI.
Marks: 2

Question: What is computer vision?
Answer: Computer vision is a field of AI that trains computers to interpret and understand the visual world. It involves methods for acquiring, processing, analyzing, and understanding digital images to produce numerical or symbolic information.
Marks: 2

Question: Explain the concept of a decision tree in machine learning.
Answer: A decision tree is a flowchart-like structure where each internal node represents a "test" on an attribute, each branch represents the outcome of the test, and each leaf node represents a class label. It's a popular method for both classification and regression tasks in machine learning.
Marks: 2

Question: What is the Moravec's paradox?
Answer: Moravec's paradox states that high-level reasoning requires very little computation, while low-level sensorimotor skills require enormous computational resources. In other words, it's easier for AI to mimic complex human thinking than basic human perception and mobility.
Marks: 2

Question: Describe the concept of a neural network's activation function.
Answer: An activation function in a neural network determines whether a neuron should be activated or not by calculating the weighted sum and adding bias to it. It introduces non-linear properties to the network, allowing it to learn complex patterns. Common activation functions include ReLU, Sigmoid, and Tanh.
Marks: 2

Question: What is transfer learning in the context of machine learning?
Answer: Transfer learning is a machine learning method where a model developed for a task is reused as the starting point for a model on a second task. It's popular in deep learning where pre-trained models are used as a starting point on computer vision and natural language processing tasks.
Marks: 2

Question: Explain the concept of overfitting in machine learning.
Answer: Overfitting occurs when a statistical model fits exactly against its training data. When this happens, the algorithm unfortunately cannot perform accurately against unseen data, defeating its purpose. It's often addressed through techniques like cross-validation, regularization, and ensuring sufficient training data.
Marks: 2

Question: What is the Turing Test?
Answer: The Turing Test, proposed by Alan Turing in 1950, is a test of a machine's ability to exhibit intelligent behavior equivalent to, or indistinguishable from, that of a human. In the test, a human evaluator would judge natural language conversations between a human and a machine designed to generate human-like responses.
Marks: 2

Question: Explain the concept of a support vector machine (SVM).
Answer: A Support Vector Machine is a supervised machine learning algorithm used for both classification and regression. It works by finding the hyperplane that best divides a dataset into classes. SVMs are particularly effective in high-dimensional spaces and are memory-efficient.
Marks: 2

Question: What is reinforcement learning?
Answer: Reinforcement learning is an area of machine learning where an agent learns to make decisions by taking actions in an environment to maximize some notion of cumulative reward. It's based on the idea of learning through interaction with the environment, similar to how humans learn.
Marks: 2

Question: Describe the concept of backpropagation in neural networks.
Answer: Backpropagation is an algorithm used to train neural networks. It calculates the gradient of the loss function with respect to each weight by the chain rule, iterating backwards from the output layer to avoid redundant calculations of intermediate terms in the chain rule.
Marks: 3

Question: What is the difference between supervised and unsupervised learning?
Answer: In supervised learning, the algorithm learns from labeled data, meaning the desired output is known. In unsupervised learning, the algorithm learns from unlabeled data, trying to find patterns or structures within the data without predefined labels.
Marks: 2

Question: Explain the concept of a Generative Adversarial Network (GAN).
Answer: A GAN is a class of machine learning frameworks where two neural networks contest with each other in a game. The generator network creates new data instances, while the discriminator network evaluates them for authenticity. The networks are trained simultaneously, with the generator learning to produce more realistic data.
Marks: 3

Question: What is the AI winter?
Answer: The AI winter refers to periods of reduced funding and interest in artificial intelligence research. There have been several AI winters, notably in the 1970s and 1980s, often following cycles of hype and subsequent disappointment in AI capabilities.
Marks: 2

Question: Describe the concept of a Markov Decision Process (MDP).
Answer: A Markov Decision Process is a mathematical framework for modeling decision-making in situations where outcomes are partly random and partly under the control of a decision-maker. It's widely used in reinforcement learning for modeling the environment.
Marks: 2

Question: What is the difference between a recurrent neural network (RNN) and a convolutional neural network (CNN)?
Answer: RNNs are designed to work with sequence data and can use their internal state (memory) to process sequences of inputs. CNNs, on the other hand, are primarily used for processing grid-like data such as images, using convolutional layers to detect local features.
Marks: 3

Question: Explain the concept of feature extraction in machine learning.
Answer: Feature extraction is the process of reducing the number of resources required to describe a large set of data. It involves reducing the number of features in a dataset while still accurately describing the original data. This is crucial for improving model performance and reducing overfitting.
Marks: 2

Question: What is the Turing completeness in the context of AI?
Answer: Turing completeness refers to the ability of a computational system to simulate a Turing machine. In AI, a system that is Turing complete can, in principle, solve any computational problem, given enough time and memory.
Marks: 2

Question: Describe the concept of ensemble learning.
Answer: Ensemble learning is a machine learning paradigm where multiple models (often called "weak learners") are trained to solve the same problem and combined to get better results. Common methods include bagging, boosting, and stacking.
Marks: 2

Question: What is the difference between AI, machine learning, and deep learning?
Answer: AI is the broader concept of machines being able to carry out tasks in a way that we would consider "smart". Machine learning is a subset of AI that focuses on the ability of machines to receive data and learn for themselves. Deep learning is a subset of machine learning that uses neural networks with multiple layers.
Marks: 3

Question: Explain the concept of a confusion matrix in machine learning.
Answer: A confusion matrix is a table used to describe the performance of a classification model on a set of test data for which the true values are known. It allows visualization of the performance of an algorithm, showing the ways in which your classification model is confused when it makes predictions.
Marks: 2

Question: What is the AI effect?
Answer: The AI effect refers to the phenomenon where once an AI technique reaches mainstream use, it's no longer considered AI. This leads to a constantly moving definition of what constitutes AI, as achievements in the field quickly become considered routine or mundane.
Marks: 2

Question: Describe the concept of adversarial attacks in AI.
Answer: Adversarial attacks are attempts to fool models by supplying deceptive input. For example, in image classification, an adversarial attack might involve adding carefully constructed noise to an image to cause a model to misclassify it, even though the change is imperceptible to humans.
Marks: 2

Question: What is the difference between a rule-based system and a machine learning system?
Answer: Rule-based systems follow a set of human-created rules to make decisions, while machine learning systems learn patterns from data to make decisions. Rule-based systems are more interpretable but less flexible, while machine learning systems can handle more complex patterns but may be less interpretable.
Marks: 2

Question: Explain the concept of a Boltzmann machine.
Answer: A Boltzmann machine is a type of stochastic recurrent neural network. It can be seen as the stochastic, generative counterpart of Hopfield nets. It can learn internal representations and solve combinatorial optimization problems.
Marks: 2

Question: What is the Chinese room argument in AI?
Answer: The Chinese room argument, proposed by John Searle, is a thought experiment designed to argue against the possibility of true artificial intelligence. It suggests that a computer program can't be said to truly "understand" or be conscious, even if it can convince a human that it does.
Marks: 2

Question: Describe the concept of a knowledge graph in AI.
Answer: A knowledge graph is a way to store and represent knowledge in a graph structure, using nodes to represent entities and edges to represent relationships between entities. It's used in AI for tasks like question answering, recommendation systems, and semantic search.
Marks: 2

Question: What is the difference between symbolic AI and subsymbolic AI?
Answer: Symbolic AI uses high-level symbolic (human-readable) representations of problems, logic, and search methods. Subsymbolic AI, which includes neural networks, uses low-level, non-symbolic representations and statistical methods to learn patterns from data.
Marks: 2

Question: Explain the concept of transfer learning in deep learning.
Answer: Transfer learning is a technique where a model developed for a task is reused as the starting point for a model on a second task. It's particularly useful in deep learning where pre-trained models can be fine-tuned on smaller, specific datasets, saving time and computational resources.
Marks: 2

Question: What is the AI alignment problem?
Answer: The AI alignment problem refers to the challenge of ensuring that artificial intelligence systems behave in accordance with human values and intentions. It's a crucial consideration in the development of advanced AI systems to ensure they benefit humanity.
Marks: 2

Question: Describe the concept of a neural architecture search (NAS).
Answer: Neural Architecture Search is a technique for automating the design of artificial neural networks. It uses machine learning techniques to optimize the architecture of a neural network, potentially finding designs that outperform human-created architectures.
Marks: 2

Question: What is explainable AI (XAI)?
Answer: Explainable AI refers to methods and techniques in the application of AI such that the results of the solution can be understood by humans. It contrasts with the concept of the "black box" in machine learning where even the designers cannot explain why the AI arrived at a specific decision.
Marks: 2

Question: Explain the concept of federated learning.
Answer: Federated learning is a machine learning technique that trains an algorithm across multiple decentralized edge devices or servers holding local data samples, without exchanging them. This approach addresses critical issues such as data privacy, security, access rights, and access to heterogeneous data.
Marks: 2

Question: What is the difference between a parametric and non-parametric model in machine learning?
Answer: Parametric models have a fixed number of parameters, regardless of the size of the training set (e.g., linear regression). Non-parametric models' complexity grows with the size of the training set (e.g., k-nearest neighbors). Non-parametric models are more flexible but may require more data.
Marks: 3

Question: Describe the concept of a Gaussian process in machine learning.
Answer: A Gaussian process is a probabilistic machine learning method used for regression and probabilistic classification. It's a collection of random variables, any finite number of which have a joint Gaussian distribution. It's often used for modeling uncertainty in predictions.
Marks: 2

Question: What is the difference between inductive and deductive reasoning in AI?
Answer: Inductive reasoning in AI involves drawing general conclusions from specific observations, useful in machine learning. Deductive reasoning involves drawing specific conclusions based on general rules, often used in rule-based AI systems and logic programming.
Marks: 2

Question: Explain the concept of meta-learning in AI.
Answer: Meta-learning, also known as "learning to learn," is an AI paradigm where a model learns how to learn, improving its learning algorithm over multiple learning episodes. It aims to design models that can learn new skills or adapt to new environments rapidly with a few training examples.
Marks: 2

Question: What is the concept of attention in deep learning? 
Answer: Attention is a mechanism that allows a model to focus on specific parts of the input data when processing it, rather than considering the entire input equally. It's often used in natural language processing and computer vision tasks. 
Marks: 2

Question: Describe the concept of a Long Short-Term Memory (LSTM) network. 
Answer: An LSTM network is a type of recurrent neural network that uses memory cells to learn long-term dependencies in data. It's particularly useful for modeling temporal relationships in sequential data. 
Marks: 3

Question: What is the difference between a type I and type II error in machine learning? 
Answer: A type I error occurs when a model incorrectly rejects a true null hypothesis, while a type II error occurs when a model fails to reject a false null hypothesis. Type I errors are often considered more severe. 
Marks: 2

Question: Explain the concept of a gradient in machine learning. 
Answer: A gradient is a measure of how much a model's parameters need to change to minimize the loss function. It's used in optimization algorithms like stochastic gradient descent to update the model's parameters. 
Marks: 2

Question: What is the concept of overfitting in machine learning? 
Answer: Overfitting occurs when a model is too complex and performs well on the training data but poorly on new, unseen data. It's often addressed through regularization techniques and early stopping. 
Marks: 2

Question: Describe the concept of a decision tree in machine learning. 
Answer: A decision tree is a tree-like model that splits data into subsets based on features and their values. It's often used for classification and regression tasks. 
Marks: 2

Question: What is the difference between a generative and discriminative model in machine learning? 
Answer: A generative model generates new data samples, while a discriminative model predicts a label or class given input data. Generative models are often used for tasks like image generation, while discriminative models are used for tasks like image classification. 
Marks: 2

Question: Explain the concept of a kernel in machine learning. 
Answer: A kernel is a function that maps input data into a higher-dimensional space, allowing for non-linear relationships to be modeled. It's often used in support vector machines and other kernel-based methods. 
Marks: 2

Question: What is the concept of a bias-variance tradeoff in machine learning? 
Answer: The bias-variance tradeoff refers to the tradeoff between the error introduced by a model's simplifying assumptions (bias) and the error introduced by the noise in the data (variance). A good model should balance these two sources of error. 
Marks: 2

Question: Describe the concept of a random forest in machine learning. 
Answer: A random forest is an ensemble learning method that combines multiple decision trees to improve the accuracy and robustness of predictions. It's often used for classification and regression tasks. 
Marks: 2

Question: What is the difference between a supervised and unsupervised learning algorithm? 
Answer: A supervised learning algorithm is trained on labeled data, while an unsupervised learning algorithm is trained on unlabeled data. Supervised learning is often used for tasks like image classification, while unsupervised learning is used for tasks like clustering. 
Marks: 2

Question: Explain the concept of a neural network's activation function. 
Answer: An activation function is a mathematical function that introduces non-linearity into a neural network, allowing it to learn complex relationships between inputs and outputs. Common activation functions include ReLU, Sigmoid, and Tanh. 
Marks: 2

Question: What is the concept of a batch normalization in deep learning? 
Answer: Batch normalization is a technique that normalizes the input data for each layer in a neural network, improving the stability and speed of training. It's often used in deep neural networks. 
Marks: 2

Question: Describe the concept of a recurrent neural network (RNN) in deep learning. 
Answer: An RNN is a type of neural network that processes sequential data, using feedback connections to maintain a hidden state that captures information from previous time steps. It's often used for tasks like language modeling and machine translation. 
Marks: 3

Question: What is the difference between a convolutional neural network (CNN) and a recurrent neural network (RNN)? 
Answer: A CNN is a type of neural network that processes grid-like data, using convolutional layers to extract features. An RNN is a type of neural network that processes sequential data, using recurrent connections to maintain a hidden state. 
Marks: 2

Question: What is the difference between supervised and reinforcement learning?
Answer: Supervised learning involves learning from labeled data to make predictions, while reinforcement learning involves learning by interacting with an environment to maximize cumulative rewards.
Marks: 2

Question: Explain the concept of dropout in neural networks.
Answer: Dropout is a regularization technique used in neural networks to prevent overfitting. During training, randomly selected neurons are ignored (dropped out), forcing the network to learn more robust features.
Marks: 2

Question: What is the role of a loss function in machine learning?
Answer: A loss function measures how well a model's predictions match the actual data. It provides a way to quantify the error and is used by optimization algorithms to update the model's parameters.
Marks: 2

Question: Describe the concept of reinforcement learning in AI.
Answer: Reinforcement learning involves training an agent to make decisions by taking actions in an environment to maximize a cumulative reward. It uses trial and error to learn optimal policies.
Marks: 3

Question: What is a convolutional neural network (CNN)?
Answer: A CNN is a type of deep learning model designed for processing grid-like data such as images. It uses convolutional layers to automatically and adaptively learn spatial hierarchies of features.
Marks: 2

Question: Explain the concept of a perceptron in machine learning.
Answer: A perceptron is a simple type of artificial neuron used in machine learning. It computes a weighted sum of its input features and applies an activation function to produce an output.
Marks: 2

Question: What is the difference between batch and stochastic gradient descent?
Answer: Batch gradient descent computes the gradient using the entire dataset, while stochastic gradient descent updates the model parameters using a single training example at a time. Mini-batch gradient descent is a compromise between the two.
Marks: 2

Question: Describe the concept of an autoencoder in deep learning.
Answer: An autoencoder is a type of neural network used to learn efficient codings of data. It consists of an encoder that compresses the data and a decoder that reconstructs the data from the compressed representation.
Marks: 3

Question: What is the importance of feature scaling in machine learning?
Answer: Feature scaling is the process of normalizing the range of features in data. It improves the performance and convergence speed of optimization algorithms by ensuring that all features contribute equally to the model.
Marks: 2

Question: Explain the concept of a softmax function.
Answer: The softmax function is an activation function used in the output layer of a neural network for multi-class classification. It converts raw scores (logits) into probabilities, with the sum of the probabilities equal to one.
Marks: 2

Question: What is the concept of data augmentation in machine learning?
Answer: Data augmentation is a technique used to increase the diversity of training data without collecting new data. It involves creating new data points from existing ones by applying transformations such as rotation, scaling, and flipping.
Marks: 2

Question: Describe the concept of a recurrent neural network's hidden state.
Answer: The hidden state in an RNN is a set of memory cells that capture information from previous time steps. It allows the network to maintain context and dependencies over sequences of inputs.
Marks: 3

Question: What is the purpose of a learning rate in optimization algorithms?
Answer: The learning rate controls the step size at each iteration of the optimization algorithm. It determines how quickly or slowly the model parameters are updated, affecting the convergence speed and stability of training.
Marks: 2

Question: Explain the concept of transfer learning in deep learning.
Answer: Transfer learning involves using a pre-trained model on a new, related task. The pre-trained model's knowledge is transferred to the new task, reducing the amount of training data and time required.
Marks: 2

Question: What is the role of a hyperparameter in machine learning?
Answer: A hyperparameter is a parameter whose value is set before training and controls the learning process. Examples include learning rate, batch size, and the number of layers in a neural network. Hyperparameter tuning is crucial for model performance.
Marks: 2

Question: Describe the concept of an embedding in deep learning.
Answer: An embedding is a learned representation of data, where items are mapped to vectors in a continuous vector space. Embeddings are commonly used in natural language processing to represent words or phrases with dense vectors.
Marks: 3

Question: What is a hyperparameter in machine learning?
Answer: A hyperparameter is a parameter whose value is set before the learning process begins. Hyperparameters control the behavior of the training algorithm and model architecture, such as learning rate, batch size, and the number of layers in a neural network.
Marks: 2

Question: Explain the concept of gradient clipping.
Answer: Gradient clipping is a technique used to prevent exploding gradients in neural networks. It involves capping the gradients during the backpropagation step to a maximum value, ensuring stable and effective training.
Marks: 2

Question: What is the difference between precision and recall in the context of a classification model?
Answer: Precision is the ratio of true positive predictions to the total predicted positives, measuring the accuracy of positive predictions. Recall is the ratio of true positive predictions to the total actual positives, measuring the model's ability to identify all relevant instances.
Marks: 2

Question: Describe the concept of a dropout rate in neural networks.
Answer: The dropout rate is the probability of dropping out (ignoring) a neuron during training in a neural network. This regularization technique prevents overfitting by ensuring that the model does not rely too heavily on any single neuron.
Marks: 3

Question: What is the purpose of an optimizer in machine learning?
Answer: An optimizer is an algorithm used to update the model parameters in order to minimize the loss function. Common optimizers include stochastic gradient descent (SGD), Adam, and RMSprop.
Marks: 2

Question: Explain the concept of cross-validation in machine learning.
Answer: Cross-validation is a technique used to evaluate the generalization performance of a model. It involves splitting the dataset into multiple folds, training the model on some folds, and validating it on the remaining folds, averaging the performance across all folds.
Marks: 2

Question: What is the difference between underfitting and overfitting in machine learning?
Answer: Underfitting occurs when a model is too simple and cannot capture the underlying patterns in the data, resulting in poor performance. Overfitting occurs when a model is too complex and fits the training data too closely, performing well on training data but poorly on new, unseen data.
Marks: 2

Question: Describe the concept of a learning curve in machine learning.
Answer: A learning curve is a plot that shows the performance of a model on the training and validation datasets over time or as a function of the number of training samples. It helps diagnose issues like underfitting, overfitting, and whether the model is improving with more data.
Marks: 3

Question: What is the purpose of early stopping in training neural networks?
Answer: Early stopping is a regularization technique used during the training of neural networks to prevent overfitting. It works by monitoring the performance of the model on a validation set. As training progresses, if the performance on the validation set starts to degrade (i.e., validation error increases), early stopping stops the training process early to prevent the model from learning noise from the training data that may not generalize well to new, unseen data. By halting training at the right moment, early stopping ensures that the model generalizes well and improves its ability to make accurate predictions on new data.
Marks : 5

Question: Explain the concept of one-hot encoding.
Answer: One-hot encoding is a method used to convert categorical variables into a format that can be used for machine learning algorithms. In this technique, each category is represented as a binary vector with a length equal to the number of categories in the variable. Only one element of the vector is set to 1 (indicating the presence of that category), and all other elements are set to 0. This representation allows the categorical variable to be effectively used as input for machine learning models, where algorithms interpret each category independently and do not assume any ordinal relationship between categories.
Marks : 5

Question: What is the purpose of a validation set in machine learning?
Answer: A validation set plays a crucial role in the development and evaluation of machine learning models. It is a subset of the dataset that is used to evaluate the performance of the model during training. Unlike the training set, which is used to train the model's parameters, the validation set is used to tune hyperparameters, such as learning rate or regularization strength, and to assess the model's ability to generalize to new, unseen data. By providing an unbiased estimate of the model's performance on data that it has not been trained on, the validation set helps in selecting the best model architecture and hyperparameter settings.
Marks : 5

Question: Describe the concept of ensemble learning.
Answer: Ensemble learning is a powerful technique in machine learning that aims to improve the performance of a model by combining multiple models together. Instead of relying on a single model's predictions, ensemble methods generate predictions by aggregating the outputs of several base models, known as ensemble members. There are several popular ensemble methods, including bagging, boosting, and stacking. Bagging (Bootstrap Aggregating) involves training each base model on a randomly sampled subset of the training data with replacement. Boosting sequentially trains base models, giving more weight to examples that were misclassified in previous models. Stacking combines predictions from multiple models using a meta-model that learns to combine their outputs optimally. Ensemble methods can significantly enhance prediction accuracy and robustness, particularly in complex and high-dimensional datasets.
Marks: 5

Question: What is the role of a cost function in machine learning?
Answer: A cost function, also known as a loss function, plays a central role in machine learning by quantifying the difference between the predicted output of a model and the actual target values in the training data. The goal of machine learning is to minimize this difference, or error, which is measured by the cost function. Different types of cost functions are used depending on the task, such as mean squared error for regression problems and cross-entropy loss for classification tasks. Optimization algorithms, such as gradient descent, use the gradients of the cost function with respect to the model parameters to update them iteratively during training, aiming to minimize the cost function and improve the model's predictive accuracy.
Marks : 5

Question: Explain the concept of a learning rate in optimization algorithms.
Answer: The learning rate is a critical hyperparameter in optimization algorithms used for training machine learning models. It controls the size of the steps taken during gradient descent or other optimization processes when updating the model parameters. A high learning rate allows for faster convergence but may risk overshooting the optimal solution or causing instability in training. Conversely, a low learning rate leads to slower convergence but may result in more stable and accurate learning. Choosing an appropriate learning rate is crucial as it directly impacts the efficiency, speed, and quality of model training. Techniques such as learning rate schedules and adaptive learning rates (e.g., Adam optimizer) are often employed to dynamically adjust the learning rate during training to optimize model performance.
Marks : 5

Question: What is the difference between a linear and non-linear activation function in neural networks?
Answer: Activation functions are crucial components in neural networks that introduce non-linearity, allowing them to model complex relationships between inputs and outputs. A linear activation function produces an output that is directly proportional to its input, resulting in a network that can only represent linear transformations of the input data. In contrast, non-linear activation functions, such as ReLU (Rectified Linear Unit), Sigmoid, and Tanh, transform the input data into non-linear outputs. This non-linearity enables neural networks to learn and approximate any complex function, making them suitable for a wide range of tasks, including image recognition, natural language processing, and reinforcement learning.
Marks: 5

Question: Describe the concept of a support vector machine (SVM) in machine learning.
Answer: A Support Vector Machine (SVM) is a powerful supervised learning algorithm used for both classification and regression tasks. It works by finding the optimal hyperplane that best separates the data into different classes in a high-dimensional space. The hyperplane is chosen to maximize the margin, or distance, between the closest data points of different classes, ensuring robust generalization to unseen data. SVMs are effective in handling high-dimensional data and are particularly well-suited for problems where the data is not linearly separable. They can also be extended using kernel methods to handle non-linear decision boundaries by implicitly mapping the input data into a higher-dimensional feature space. SVMs have been widely used in various applications, including image classification, text categorization, and bioinformatics.
Marks: 5

Question: What is the purpose of a bias term in a neural network?
Answer: In the context of neural networks, a bias term is an additional parameter added to each neuron that allows the model to better fit the data by shifting the activation function. The bias term effectively allows the activation function to be adjusted independently of the input data, helping the model learn and represent complex patterns and relationships. Without bias terms, the model would be constrained to pass through the origin (0,0) on a graph, limiting its ability to accurately model data that does not have a natural zero point. By incorporating bias terms, neural networks gain flexibility and can more effectively learn to discriminate between different classes or predict continuous values, enhancing their overall performance and accuracy.
Marks: 5

Question: Explain the concept of a hyperparameter grid search.
Answer: Hyperparameter grid search is a systematic approach used to find the optimal set of hyperparameters for a machine learning model. It involves defining a grid of hyperparameter values to explore, such as learning rate, batch size, and the number of layers in a neural network. For each combination of hyperparameters in the grid, the model is trained and evaluated using cross-validation or a separate validation set. The performance metric, such as accuracy or mean squared error, is then recorded for each combination. The goal of hyperparameter grid search is to identify the hyperparameter values that yield the best performance on unseen data. While grid search is effective, it can be computationally expensive, especially with a large number of hyperparameters and values. Techniques like randomized search or Bayesian optimization are alternatives that can be more efficient in certain scenarios.
Marks: 5

Question: What is the difference between a shallow and deep neural network?
Answer: The main distinction between a shallow and deep neural network lies in their architecture and complexity. A shallow neural network typically consists of only one or two hidden layers between the input and output layers. In contrast, a deep neural network has multiple hidden layers, often ranging from three to hundreds or even thousands in deep learning applications. The depth of a neural network allows it to learn hierarchical representations of data, capturing intricate patterns and relationships that may not be discernible with fewer layers. Deep neural networks excel in handling complex tasks such as image and speech recognition, natural language processing, and reinforcement learning, where extracting and understanding intricate features from the input data is crucial for accurate predictions. However, deep networks require more computational resources for training and may be prone to overfitting if not properly regularized or trained with sufficient data.
Marks: 5
